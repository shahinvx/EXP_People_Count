{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Local_Deep Counting.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ryr6TWgRzX0Z4nsKDdbG6qoT23RE9hIB","authorship_tag":"ABX9TyOkxtf6xADBGSIM9JNA7rSZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_nNVSnp28HW","executionInfo":{"status":"ok","timestamp":1627648178202,"user_tz":-360,"elapsed":405,"user":{"displayName":"Md. Mahmudul Hasan Shahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRx95iiEiz_iqtQvGSnh1i2sStbv9xjQgHDQcM=s64","userId":"04675764273122559940"}},"outputId":"2fbc82d1-07f1-4de1-a4ff-99f3400af678"},"source":["%cd /content/drive/My Drive/Google Colab/Computer Vision/EXP/People_Counting\n","%ls"],"execution_count":68,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Google Colab/Computer Vision/EXP/People_Counting\n"," \u001b[0m\u001b[01;34minputs\u001b[0m/  'Local_Deep Counting.ipynb'   \u001b[01;34moutputs\u001b[0m/   \u001b[01;34mutils\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CYYS1a_q3DDe","executionInfo":{"status":"ok","timestamp":1627648178823,"user_tz":-360,"elapsed":4,"user":{"displayName":"Md. Mahmudul Hasan Shahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRx95iiEiz_iqtQvGSnh1i2sStbv9xjQgHDQcM=s64","userId":"04675764273122559940"}}},"source":["import cv2\n","import os\n","import time\n","import sys\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","import dlib\n","from google.colab.patches import cv2_imshow\n","\n","import imutils\n","from imutils.video import VideoStream\n","from imutils.video import FPS\n","from scipy.spatial import distance as dist\n","from collections import OrderedDict"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlU96l6G3M9V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627648179807,"user_tz":-360,"elapsed":987,"user":{"displayName":"Md. Mahmudul Hasan Shahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRx95iiEiz_iqtQvGSnh1i2sStbv9xjQgHDQcM=s64","userId":"04675764273122559940"}},"outputId":"9d6196ac-d7c5-4985-88aa-84088f3757c4"},"source":["#streamIP = \"http://185.23.67.125:8080/stream/input.mjpeg\"\n","\n","inputFile = \"./inputs/test_3.mp4\"\n","outputFile = \"./outputs/output.avi\"\n","\n","scaleFactor = 1 / 255.0\n","\n","# minimum probability of weak detections\n","minConfidence = 0.3\n","\n","# threshold when applying non-maxima suppression\n","threshold = 0.2\n","\n","elapsedFrames = 0\n","\n","# switch between detection and tracking\n","# set number of frames to skip\n","skipFrames = 10\n","\n","FPSUpdate = 200\n","liveFPS = 0\n","\n","inputWidth = 416 \n","inputHeight = 416  \n","\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","\n","class_file =  './utils/detect.names'\n","cfg_file = './utils/model.cfg'\n","weights_file = './utils/model.weights'\n","\n","modelName = \"Shahin VX\"\n","\n","status = \"off\"\n","\n","writer = None\n","\n","# vs = cv2.VideoCapture(streamIP)\n","\n","vs = cv2.VideoCapture(inputFile)\n","\n","prop = cv2.CAP_PROP_FRAME_COUNT\n","totalFrames = int(vs.get(prop))\n","print(\"--> Total frames in input video {} \".format(totalFrames))\n","\n","H = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","W = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n","\n","limitIn = int(H/2 + H/9)\n","limitOut = int(H/2 - H/9)\n","\n","print(W, H)\n","\n","# load the COCO class labels:\n","classNames = open(class_file).read().strip().split(\"\\n\")\n","\n","# Load the serialized caffe model from disk:\n","print(\"--> Loading model ...\")\n","\n","net = cv2.dnn.readNetFromDarknet(cfg_file, weights_file)\n","\n","print(\"--> Loading model ... done !\")\n","\n"],"execution_count":70,"outputs":[{"output_type":"stream","text":["[INFO] 518 total frames in video\n","1920 1080\n","--> Loading model ...\n","--> Loading model ... done !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xBgapFaX5pZY","executionInfo":{"status":"ok","timestamp":1627648179808,"user_tz":-360,"elapsed":4,"user":{"displayName":"Md. Mahmudul Hasan Shahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRx95iiEiz_iqtQvGSnh1i2sStbv9xjQgHDQcM=s64","userId":"04675764273122559940"}}},"source":["#!pip install opencv-contrib-python==3.4.13.47 --force-reinstall"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzYxKmcw3OgF","executionInfo":{"status":"ok","timestamp":1627648424224,"user_tz":-360,"elapsed":244420,"user":{"displayName":"Md. Mahmudul Hasan Shahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRx95iiEiz_iqtQvGSnh1i2sStbv9xjQgHDQcM=s64","userId":"04675764273122559940"}},"outputId":"c548d1d6-f510-4811-f3db-7e437847cca7"},"source":["# Get the output layer names:\n","def getOutputLayers(net):\n","    layerNames = net.getLayerNames()\n","    layerNames = [layerNames[i[0] - 1]for i in net.getUnconnectedOutLayers()]\n","    return layerNames\n","\n","# function to draw bounding box on the detected object\n","def drawBoundingBox(frame, box, centroid, color):\n","    (startX, startY, endX, endY) = box\n","\n","    cv2.rectangle(frame, (int(startX), int(startY)), (int(\n","        endX), int(endY)), color, thickness=2)\n","\n","# return coordinates of the center (centroid) of a bbox\n","def computeCentroid(box):\n","    (startX, startY, endX, endY) = box\n","    return np.array([startX + ((endX - startX)/2), startY + ((endY - startY)/2)])\n","\n","class TrackableObject:\n","    def __init__(self, objectID, centroid, zone):\n","        self.objectID = objectID\n","        self.centroids = [centroid]\n","        self.zone = zone\n","\n","        self.counted = False\n","\n","class CentroidTracker:\n","    def __init__(self, maxDisappeared=30, maxDistance=30):\n","\n","        self.nextObjectID = 0\n","        self.objects = OrderedDict()\n","        self.disappeared = OrderedDict()\n","\n"," \n","        self.maxDisappeared = maxDisappeared\n","\n","        self.maxDistance = maxDistance\n","\n","    def register(self, centroid):\n","        self.objects[self.nextObjectID] = centroid\n","        self.disappeared[self.nextObjectID] = 0\n","        self.nextObjectID += 1\n","\n","    def deregister(self, objectID):\n","        del self.objects[objectID]\n","        del self.disappeared[objectID]\n","\n","    def update(self, rects):\n","        if len(rects) == 0:\n","            for objectID in list(self.disappeared.keys()):\n","                self.disappeared[objectID] += 1\n","\n","                if self.disappeared[objectID] > self.maxDisappeared:\n","                    self.deregister(objectID)\n","\n","            return self.objects\n","\n","        # initialize an array of input centroids for the current frame\n","        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n","\n","        # loop over the bounding box rectangles\n","        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n","            cX = int((startX + endX) / 2.0)\n","            cY = int((startY + endY) / 2.0)\n","            inputCentroids[i] = (cX, cY)\n","\n","        if len(self.objects) == 0:\n","            for i in range(0, len(inputCentroids)):\n","                self.register(inputCentroids[i])\n","\n","        else:\n","            # grab the set of object IDs and corresponding centroids\n","            objectIDs = list(self.objects.keys())\n","            objectCentroids = list(self.objects.values())\n","\n","            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n","\n","\n","            rows = D.min(axis=1).argsort()\n","\n","            cols = D.argmin(axis=1)[rows]\n","\n","\n","            usedRows = set()\n","            usedCols = set()\n","\n"," \n","            for (row, col) in zip(rows, cols):\n","\n","                if row in usedRows or col in usedCols:\n","                    continue\n","\n","                if D[row, col] > self.maxDistance:\n","                    continue\n","\n","                objectID = objectIDs[row]\n","                self.objects[objectID] = inputCentroids[col]\n","                self.disappeared[objectID] = 0\n","\n","                usedRows.add(row)\n","                usedCols.add(col)\n","\n","\n","            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n","            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n","\n","            if D.shape[0] >= D.shape[1]:\n","                for row in unusedRows:\n","\n","                    objectID = objectIDs[row]\n","                    self.disappeared[objectID] += 1\n","\n","                    if self.disappeared[objectID] > self.maxDisappeared:\n","                        self.deregister(objectID)\n","\n","            else:\n","                for col in unusedCols:\n","                    self.register(inputCentroids[col])\n","\n","        # return the set of trackable objects\n","        return self.objects\n","\n","# object detection using SSD\n","def detect(frame, layerOutputs):\n","    # loop over the detections\n","    for output in layerOutputs:\n","        for detection in output:\n","          \n","            scores = detection[5:]\n","            classId = np.argmax(scores)\n","            confidence = scores[classId]\n","\n","            # Filter out weak predictions:\n","            if confidence > minConfidence:\n","                box = detection[0:4] * np.array([W, H, W, H])\n","                (centerX, centerY, width, height) = box.astype(\"int\")\n","\n","                x = int(centerX - (width / 2))\n","                y = int(centerY - (height / 2))\n","\n","                boxes.append([x, y, int(width), int(height)])\n","                confidences.append(float(confidence))\n","                classIds.append(classId)\n","\n","\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, minConfidence, threshold)\n","\n","    for i in indices:\n","        i = i[0]\n","        \n","        if classIds[i] == 0:\n","            # get coordinates of the bbox\n","            box = boxes[i]\n","            left = box[0]\n","            top = box[1]\n","            width = box[2]\n","            height = box[3]\n","            right = left + width\n","            bottom = top + height\n","\n","            box = [left, top, right, bottom]\n","     \n","            tracker = dlib.correlation_tracker()\n","            rect = dlib.rectangle(int(left), int(\n","                top), int(right), int(bottom))\n","\n","            tracker.start_track(frame, rect)\n","\n","            trackers.append(tracker)\n","\n","            rects.append(box)\n","\n","            centroid = computeCentroid(box)\n","           \n","            drawBoundingBox(frame, box, centroid, color=(0, 0, 255))\n","\n","            cv2.putText(frame, status, (0, 115), font,\n","                        0.5, (0, 255, 0), 1, cv2.LINE_AA)\n","            \n","# object tracking using dlib and centroid tracker\n","def track(frame, trackers):\n","    frame_num = 0\n","    for tracker in trackers:\n","        status = \"Tracking .\"\n","        tracker.update(frame)\n","\n","        pos = tracker.get_position()\n","\n","        # unpack the position object\n","        left = int(pos.left())\n","        top = int(pos.top())\n","        right = int(pos.right())\n","        bottom = int(pos.bottom())\n","\n","        box = [left, top, right, bottom]\n","\n","        rects.append(box)\n","\n","        centroid = computeCentroid(box)\n","\n","        drawBoundingBox(frame, box, centroid, color=(0, 128, 255))\n","\n","        if frame_num % 2==0:\n","          status = \"Tracking ...\"\n","\n","        cv2.putText(frame, status, (0, 95), font,\n","                    0.5, (255, 0, 0), 1, cv2.LINE_AA)\n","        frame_num += 1\n","\n","# people counting logic based on zone of appearance\n","def counting(objects):\n","    \n","    global totalIn\n","    global totalOut\n","    \n","    # loop over the tracked objects\n","    for (objectID, centroid) in objects.items():\n","\n","        to = trackableObjects.get(objectID, None)\n","        \n","        if to is None:\n","            if centroid[1] >= H/2:\n","                zone = \"in\"\n","            else :\n","                zone = \"out\"\n","                \n","            to = TrackableObject(objectID, centroid, zone)\n","\n","        else:\n","            if to.zone == \"in\" :\n","                if centroid[1] < limitOut:\n","                    totalOut += 1\n","                    to.zone = \"out\"\n","                    print(\"OUT : \", totalOut)\n","                    \n","            elif to.zone == \"out\" :\n","                if centroid[1] > limitIn:\n","                    totalIn += 1\n","                    to.zone = \"in\"\n","                    print(\"IN  : \", totalIn)\n","            \n","            to.centroids.append(centroid)\n","                        \n","        trackableObjects[objectID] = to\n","        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 0, 255), -1)\n","        cv2.putText(frame, \"ID : \" + str(objectID), (centroid[0], centroid[1]+20), font,\n","                    0.6, (0, 0, 255), 1, cv2.LINE_AA)\n","\n","ct = CentroidTracker(maxDisappeared=30, maxDistance=130)\n","\n","trackers = []\n","trackableObjects = {}\n","\n","totalOut = 0\n","totalIn = 0\n","\n","fps = FPS().start()\n","totalFPS = FPS().start()\n","\n","# loop over frames from the video file stream\n","while True:\n","    # read the next frame from the file\n","    (grabbed, frame) = vs.read()\n","\n","    if not grabbed:\n","        print(\"--> Video Traking Done !!!\")\n","        break\n","    \n","    # list of detected rectangles\n","    rects = []\n","\n","    if elapsedFrames % skipFrames == 0:\n","        classIds = []\n","        confidences = []\n","        boxes = []\n","\n","        trackers = []\n","        status = \"Detecting\"\n","\n","        blob = cv2.dnn.blobFromImage(\n","            frame, scaleFactor, (inputWidth, inputHeight), swapRB=True, crop=False)\n","\n","        net.setInput(blob)\n","\n","        start = time.time()\n","        layerOutputs = net.forward(getOutputLayers(net))\n","        end = time.time()\n","\n","        detect(frame, layerOutputs)\n","\n","    else:\n","        track(frame, trackers)\n","\n","    objects = ct.update(rects)\n","    counting(objects)\n","\n","    cv2.line(frame, (0, limitIn), (W, limitIn), (0, 255, 0), 1)\n","    cv2.line(frame, (0, limitOut), (W, limitOut), (255, 0, 0), 1)\n","\n","    info = [\n","        (\"Total  \", int(totalIn) + int(totalOut)),\n","        (\"Get Out\", totalOut),\n","        (\"Get In \", totalIn)\n","    ]\n","    \n","    for (i, (k, v)) in enumerate(info):\n","        text = \"{}: {}\".format(k, v)\n","        cv2.putText(frame, text, (10, limitIn - ((i * 20) + 20)),\n","                    font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n","\n","    elapsedFrames += 1\n","    fps.update()\n","\n","    if elapsedFrames % FPSUpdate == 0:\n","        fps.stop()\n","        liveFPS = fps.fps()\n","        print(\"--> Total Time Remaining (min.sec) : {:.1f}\".format(\n","            (totalFrames-elapsedFrames) / int(liveFPS) / 60))\n","\n","        # start the frames per second throughput estimator\n","        fps = FPS().start()\n","    \n","    # draw metadatas on the frame\n","    cv2.putText(frame, \"Model : \" + modelName, (0, limitOut-15),\n","                font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n","    cv2.putText(frame, \"Resolution : \" + str(W) + \"x\" + str(H),\n","                (0, limitOut-35), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n","    cv2.putText(frame, \"FPS: {:.1f}\".format(liveFPS),\n","                (0, limitOut-55), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n","    cv2.putText(frame, \"Detection : {:.2f} sec\".format(\n","        end - start), (0, limitOut-75), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n","\n","    totalFPS.update()\n","    \n","    # show the video beeing processed live\n","    #cv2.imshow('RPI', frame)\n","    #cv2.imshow(frame)\n","\n","    # check if the video writer is None\n","    if writer is None:\n","        # initialize our video writer\n","        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","        writer = cv2.VideoWriter(outputFile, fourcc, 30, (W, H), True)\n","        print(\"Video Loading ... \")\n","\n","    # write the output frame to disk\n","    writer.write(frame)\n","    \n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","\n","totalFPS.stop()\n","print('\\n############################# Final Result ############################\\n')\n","print(\"\\t\\t --> Average FPS was : {:.2f}\".format(totalFPS.fps()))\n","print(\"\\t\\t --> Total OUT : \", totalOut)\n","print(\"\\t\\t --> Total IN  : \", totalIn)\n","print(\"\\t\\t --> Total People Count : \", int(totalIn) + int(totalOut))\n","print('\\n################################# END #################################')\n","\n","# release the file pointers\n","writer.release()\n","vs.release()\n","\n","# close any open windows\n","cv2.destroyAllWindows()"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Video Loading ... \n","OUT :  1\n","OUT :  2\n","OUT :  3\n","IN  :  1\n","--> Total Time Remaining (min.sec) : 2.6\n","OUT :  4\n","IN  :  2\n","OUT :  5\n","OUT :  6\n","OUT :  7\n","OUT :  8\n","--> Total Time Remaining (min.sec) : 1.0\n","--> Video Traking Done !!!\n","\n","############################# Final Result ############################\n","\n","\t\t --> Average FPS was : 2.13\n","\t\t --> Total OUT :  8\n","\t\t --> Total IN  :  2\n","\t\t --> Total People Count :  10\n","\n","################################# END #################################\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3biN0jPr3TGM","outputId":"2b993823-8254-454d-a48c-80694dc6e0ae"},"source":["# define helper function to display videos\n","import io \n","from IPython.display import HTML\n","from base64 import b64encode\n","def show_video(file_name, width=640):\n","  # show resulting counting video\n","  mp4 = open(file_name,'rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","  return HTML(\"\"\"\n","  <video width=\"{0}\" controls>\n","        <source src=\"{1}\" type=\"video/mp4\">\n","  </video>\n","  \"\"\".format(width, data_url))\n","\n","# convert resulting video from avi to mp4 file format\n","import os\n","path_video = os.path.join(\"outputs\",\"output.avi\")\n","%cd outputs/\n","!ffmpeg -y -loglevel panic -i output.avi result.mp4\n","%cd ..\n","\n","# output object tracking video\n","path_output = os.path.join(\"outputs\",\"result.mp4\")\n","show_video(path_output, width=960)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Google Colab/Computer Vision/EXP/People_Counting/outputs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppFRkkrJCiPY"},"source":["import io \n","from IPython.display import HTML\n","from base64 import b64encode\n","def show_video(file_name, width=640):\n","  # show resulting counting video\n","  mp4 = open(file_name,'rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","  return HTML(\"\"\"\n","  <video width=\"{0}\" controls>\n","        <source src=\"{1}\" type=\"video/mp4\">\n","  </video>\n","  \"\"\".format(width, data_url))\n","\n","show_video(path_output, width=960)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiJOyWJqtI7H"},"source":[""],"execution_count":null,"outputs":[]}]}